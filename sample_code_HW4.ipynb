{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSS107048212/AI_HW4_TSMC/blob/main/sample_code_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxX-znKjBXQu",
        "outputId": "1cf6836d-6777-4077-eac2-cae534cc65a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy matplotlib seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPPwXGrNBmGL",
        "outputId": "c6ff8c02-ebed-49ee-a29e-90497060cf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yWuxznPhATyL",
        "outputId": "55ef97bd-bd1b-4c60-959a-f43bb48acda8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import LSTM, Dense, Bidirectional\n",
        "import keras\n",
        "import seaborn as sns\n",
        "import keras.backend as K\n",
        "#from keras.layers.core import Activation\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Activation\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF8N3B5fAZT2"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "JxowlCjhnkId",
        "outputId": "b6d6320f-dd2d-44a2-b827-13586fd5c0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "viwe the data shape (20631, 27)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
              "0   1      1   -0.0007   -0.0004       100  518.67  641.82  1589.70  1400.60   \n",
              "1   1      2    0.0019   -0.0003       100  518.67  642.15  1591.82  1403.14   \n",
              "2   1      3   -0.0043    0.0003       100  518.67  642.35  1587.99  1404.20   \n",
              "3   1      4    0.0007    0.0000       100  518.67  642.35  1582.79  1401.87   \n",
              "4   1      5   -0.0019   -0.0002       100  518.67  642.37  1582.85  1406.22   \n",
              "\n",
              "      s5  ...      s13      s14     s15   s16  s17   s18  s19    s20      s21  \\\n",
              "0  14.62  ...  2388.02  8138.62  8.4195  0.03  392  2388  100  39.06  23.4190   \n",
              "1  14.62  ...  2388.07  8131.49  8.4318  0.03  392  2388  100  39.00  23.4236   \n",
              "2  14.62  ...  2388.03  8133.23  8.4178  0.03  390  2388  100  38.95  23.3442   \n",
              "3  14.62  ...  2388.08  8133.83  8.3682  0.03  392  2388  100  38.88  23.3739   \n",
              "4  14.62  ...  2388.04  8133.80  8.4294  0.03  393  2388  100  38.90  23.4044   \n",
              "\n",
              "   RUL  \n",
              "0  191  \n",
              "1  190  \n",
              "2  189  \n",
              "3  188  \n",
              "4  187  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-390188b6-0557-4572-831e-40ce3e3b253a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>...</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-390188b6-0557-4572-831e-40ce3e3b253a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-390188b6-0557-4572-831e-40ce3e3b253a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-390188b6-0557-4572-831e-40ce3e3b253a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1efe38fa-a071-4cb2-9504-8f2a43cc71b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1efe38fa-a071-4cb2-9504-8f2a43cc71b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1efe38fa-a071-4cb2-9504-8f2a43cc71b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# read training data - It is the aircraft engine run-to-failure data.\n",
        "train_df = pd.read_csv(r'./train.csv')\n",
        "print('viwe the data shape', train_df.shape)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "xKqiQUdrSisi",
        "outputId": "0b5749ba-2bec-4751-ee57-38fdb10862a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "viwe the data shape (12680, 26)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
              "0   1      1    0.0023    0.0003       100  518.67  643.02  1585.29  1398.21   \n",
              "1   1      2   -0.0027   -0.0003       100  518.67  641.71  1588.45  1395.42   \n",
              "2   1      3    0.0003    0.0001       100  518.67  642.46  1586.94  1401.34   \n",
              "3   1      4    0.0042    0.0000       100  518.67  642.44  1584.12  1406.42   \n",
              "4   1      5    0.0014    0.0000       100  518.67  642.51  1587.19  1401.92   \n",
              "\n",
              "      s5  ...     s12      s13      s14     s15   s16  s17   s18  s19    s20  \\\n",
              "0  14.62  ...  521.72  2388.03  8125.55  8.4052  0.03  392  2388  100  38.86   \n",
              "1  14.62  ...  522.16  2388.06  8139.62  8.3803  0.03  393  2388  100  39.02   \n",
              "2  14.62  ...  521.97  2388.03  8130.10  8.4441  0.03  393  2388  100  39.08   \n",
              "3  14.62  ...  521.38  2388.05  8132.90  8.3917  0.03  391  2388  100  39.00   \n",
              "4  14.62  ...  522.15  2388.03  8129.54  8.4031  0.03  390  2388  100  38.99   \n",
              "\n",
              "       s21  \n",
              "0  23.3735  \n",
              "1  23.3916  \n",
              "2  23.4166  \n",
              "3  23.3737  \n",
              "4  23.4130  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1fbe421-bf19-441c-bb9c-92600aa5055e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>...</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.02</td>\n",
              "      <td>1585.29</td>\n",
              "      <td>1398.21</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.72</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8125.55</td>\n",
              "      <td>8.4052</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>38.86</td>\n",
              "      <td>23.3735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.71</td>\n",
              "      <td>1588.45</td>\n",
              "      <td>1395.42</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.16</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8139.62</td>\n",
              "      <td>8.3803</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>39.02</td>\n",
              "      <td>23.3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.46</td>\n",
              "      <td>1586.94</td>\n",
              "      <td>1401.34</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.97</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8130.10</td>\n",
              "      <td>8.4441</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>39.08</td>\n",
              "      <td>23.4166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.44</td>\n",
              "      <td>1584.12</td>\n",
              "      <td>1406.42</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>521.38</td>\n",
              "      <td>2388.05</td>\n",
              "      <td>8132.90</td>\n",
              "      <td>8.3917</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.3737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.51</td>\n",
              "      <td>1587.19</td>\n",
              "      <td>1401.92</td>\n",
              "      <td>14.62</td>\n",
              "      <td>...</td>\n",
              "      <td>522.15</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8129.54</td>\n",
              "      <td>8.4031</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4130</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1fbe421-bf19-441c-bb9c-92600aa5055e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1fbe421-bf19-441c-bb9c-92600aa5055e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1fbe421-bf19-441c-bb9c-92600aa5055e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9282782c-6203-4798-8eb7-b90fde807a9d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9282782c-6203-4798-8eb7-b90fde807a9d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9282782c-6203-4798-8eb7-b90fde807a9d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# read test data - It is the aircraft engine operating data without failure events recorded.\n",
        "test_df = pd.read_csv(r'./test.csv')\n",
        "print('viwe the data shape', test_df.shape)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_XlKrQtWLTl"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbyj5EvyXQQP"
      },
      "outputs": [],
      "source": [
        "sequence_length = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeOZK8lOc9Gf",
        "outputId": "b96f076b-d669-4168-f99a-4f69d883a432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17631, 30, 24)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17631, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# function to reshape features into (samples, time steps, features)\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # for one id I put all the rows in a single matrix\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # Iterate over two lists in parallel.\n",
        "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
        "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
        "    # 0 50 -> from row 0 to row 50\n",
        "    # 1 51 -> from row 1 to row 51\n",
        "    # 2 52 -> from row 2 to row 52\n",
        "    # ...\n",
        "    # 111 191 -> from row 111 to 191\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "\n",
        "# pick the feature columns\n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['setting'+ str(i) for i in range(1,4)]\n",
        "sequence_cols.extend(sensor_cols)\n",
        "\n",
        "# generator for the sequences\n",
        "# transform each id of the train dataset in a sequence\n",
        "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols))\n",
        "           for id in train_df['id'].unique())\n",
        "\n",
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "print(seq_array.shape)\n",
        "\n",
        "# function to generate labels\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # For one id I put all the labels in a single matrix.\n",
        "    # For example:\n",
        "    # [[1]\n",
        "    # [4]\n",
        "    # [1]\n",
        "    # [5]\n",
        "    # [9]\n",
        "    # ...\n",
        "    # [200]]\n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # I have to remove the first seq_length labels\n",
        "    # because for one id the first sequence of seq_length size have as target\n",
        "    # the last label (the previus ones are discarded).\n",
        "    # All the next id's sequences will have associated step by step one label as target.\n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "# generate labels\n",
        "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL'])\n",
        "             for id in train_df['id'].unique()]\n",
        "\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "label_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPx1AzOan6VT",
        "outputId": "c4752fe1-403f-4db1-cdd4-dea95345262c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 30, 100)           50000     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 100)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                30200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 80251 (313.48 KB)\n",
            "Trainable params: 80251 (313.48 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "84/84 - 16s - loss: 11096.5176 - mae: 85.7831 - r2_keras: -1.9334e+00 - val_loss: 10093.8818 - val_mae: 80.9922 - val_r2_keras: -2.7041e+00 - 16s/epoch - 191ms/step\n",
            "Epoch 2/30\n",
            "84/84 - 1s - loss: 9871.3379 - mae: 79.3667 - r2_keras: -1.6099e+00 - val_loss: 9338.6846 - val_mae: 77.0204 - val_r2_keras: -2.3677e+00 - 1s/epoch - 12ms/step\n",
            "Epoch 3/30\n",
            "84/84 - 1s - loss: 9178.5029 - mae: 75.7448 - r2_keras: -1.4256e+00 - val_loss: 8701.1035 - val_mae: 73.6841 - val_r2_keras: -2.0936e+00 - 617ms/epoch - 7ms/step\n",
            "Epoch 4/30\n",
            "84/84 - 1s - loss: 8573.3467 - mae: 72.5975 - r2_keras: -1.2683e+00 - val_loss: 8135.0620 - val_mae: 70.7370 - val_r2_keras: -1.8593e+00 - 557ms/epoch - 7ms/step\n",
            "Epoch 5/30\n",
            "84/84 - 1s - loss: 8034.9204 - mae: 69.8423 - r2_keras: -1.1256e+00 - val_loss: 7625.7041 - val_mae: 68.1003 - val_r2_keras: -1.6572e+00 - 562ms/epoch - 7ms/step\n",
            "Epoch 6/30\n",
            "84/84 - 1s - loss: 7550.7012 - mae: 67.3675 - r2_keras: -9.9600e-01 - val_loss: 7163.7188 - val_mae: 65.7234 - val_r2_keras: -1.4825e+00 - 553ms/epoch - 7ms/step\n",
            "Epoch 7/30\n",
            "84/84 - 1s - loss: 7111.5889 - mae: 65.1510 - r2_keras: -8.7970e-01 - val_loss: 6747.2422 - val_mae: 63.5942 - val_r2_keras: -1.3335e+00 - 586ms/epoch - 7ms/step\n",
            "Epoch 8/30\n",
            "84/84 - 1s - loss: 6715.5742 - mae: 63.1213 - r2_keras: -7.7566e-01 - val_loss: 6369.7388 - val_mae: 61.6791 - val_r2_keras: -1.2069e+00 - 537ms/epoch - 6ms/step\n",
            "Epoch 9/30\n",
            "84/84 - 1s - loss: 6350.9692 - mae: 61.2761 - r2_keras: -6.7452e-01 - val_loss: 6031.2886 - val_mae: 59.9755 - val_r2_keras: -1.1017e+00 - 552ms/epoch - 7ms/step\n",
            "Epoch 10/30\n",
            "84/84 - 1s - loss: 6025.4839 - mae: 59.6811 - r2_keras: -5.9214e-01 - val_loss: 5725.5527 - val_mae: 58.4517 - val_r2_keras: -1.0149e+00 - 555ms/epoch - 7ms/step\n",
            "Epoch 11/30\n",
            "84/84 - 1s - loss: 5734.5371 - mae: 58.2500 - r2_keras: -5.1389e-01 - val_loss: 5453.4536 - val_mae: 57.1086 - val_r2_keras: -9.4583e-01 - 574ms/epoch - 7ms/step\n",
            "Epoch 12/30\n",
            "84/84 - 1s - loss: 5476.5366 - mae: 56.9820 - r2_keras: -4.4505e-01 - val_loss: 5209.8911 - val_mae: 55.9201 - val_r2_keras: -8.9213e-01 - 574ms/epoch - 7ms/step\n",
            "Epoch 13/30\n",
            "84/84 - 1s - loss: 5246.8857 - mae: 55.9135 - r2_keras: -3.8294e-01 - val_loss: 4993.9795 - val_mae: 54.8801 - val_r2_keras: -8.5255e-01 - 563ms/epoch - 7ms/step\n",
            "Epoch 14/30\n",
            "84/84 - 1s - loss: 5041.2197 - mae: 54.9228 - r2_keras: -3.2774e-01 - val_loss: 4802.2466 - val_mae: 53.9697 - val_r2_keras: -8.2540e-01 - 550ms/epoch - 7ms/step\n",
            "Epoch 15/30\n",
            "84/84 - 1s - loss: 4865.9800 - mae: 54.1055 - r2_keras: -2.8334e-01 - val_loss: 4634.3296 - val_mae: 53.1853 - val_r2_keras: -8.0947e-01 - 546ms/epoch - 7ms/step\n",
            "Epoch 16/30\n",
            "84/84 - 1s - loss: 4701.4155 - mae: 53.3235 - r2_keras: -2.4007e-01 - val_loss: 4486.4629 - val_mae: 52.5092 - val_r2_keras: -8.0327e-01 - 581ms/epoch - 7ms/step\n",
            "Epoch 17/30\n",
            "84/84 - 1s - loss: 4557.7173 - mae: 52.7470 - r2_keras: -2.0220e-01 - val_loss: 4358.1899 - val_mae: 51.9341 - val_r2_keras: -8.0558e-01 - 590ms/epoch - 7ms/step\n",
            "Epoch 18/30\n",
            "84/84 - 1s - loss: 4447.1948 - mae: 52.2446 - r2_keras: -1.7233e-01 - val_loss: 4247.0181 - val_mae: 51.4491 - val_r2_keras: -8.1517e-01 - 698ms/epoch - 8ms/step\n",
            "Epoch 19/30\n",
            "84/84 - 1s - loss: 4328.4756 - mae: 51.7258 - r2_keras: -1.3990e-01 - val_loss: 4151.7139 - val_mae: 51.0464 - val_r2_keras: -8.3081e-01 - 787ms/epoch - 9ms/step\n",
            "Epoch 20/30\n",
            "84/84 - 1s - loss: 4250.6465 - mae: 51.4128 - r2_keras: -1.1988e-01 - val_loss: 4070.0908 - val_mae: 50.7135 - val_r2_keras: -8.5153e-01 - 762ms/epoch - 9ms/step\n",
            "Epoch 21/30\n",
            "84/84 - 1s - loss: 4172.4702 - mae: 51.0954 - r2_keras: -1.0026e-01 - val_loss: 4001.9143 - val_mae: 50.4469 - val_r2_keras: -8.7585e-01 - 756ms/epoch - 9ms/step\n",
            "Epoch 22/30\n",
            "84/84 - 1s - loss: 4114.1602 - mae: 50.9667 - r2_keras: -8.3305e-02 - val_loss: 3944.1416 - val_mae: 50.2318 - val_r2_keras: -9.0332e-01 - 772ms/epoch - 9ms/step\n",
            "Epoch 23/30\n",
            "84/84 - 1s - loss: 4054.3279 - mae: 50.7014 - r2_keras: -6.8502e-02 - val_loss: 3896.6719 - val_mae: 50.0681 - val_r2_keras: -9.3243e-01 - 578ms/epoch - 7ms/step\n",
            "Epoch 24/30\n",
            "84/84 - 1s - loss: 4021.5955 - mae: 50.6294 - r2_keras: -5.9644e-02 - val_loss: 3856.8979 - val_mae: 49.9404 - val_r2_keras: -9.6323e-01 - 543ms/epoch - 6ms/step\n",
            "Epoch 25/30\n",
            "84/84 - 1s - loss: 3985.3186 - mae: 50.5181 - r2_keras: -4.9790e-02 - val_loss: 3824.6741 - val_mae: 49.8480 - val_r2_keras: -9.9431e-01 - 553ms/epoch - 7ms/step\n",
            "Epoch 26/30\n",
            "84/84 - 1s - loss: 3957.2361 - mae: 50.4637 - r2_keras: -4.3436e-02 - val_loss: 3798.7546 - val_mae: 49.7822 - val_r2_keras: -1.0251e+00 - 542ms/epoch - 6ms/step\n",
            "Epoch 27/30\n",
            "84/84 - 1s - loss: 3934.0005 - mae: 50.4086 - r2_keras: -3.7721e-02 - val_loss: 3777.6824 - val_mae: 49.7389 - val_r2_keras: -1.0557e+00 - 563ms/epoch - 7ms/step\n",
            "Epoch 28/30\n",
            "84/84 - 1s - loss: 3912.4749 - mae: 50.3444 - r2_keras: -3.0905e-02 - val_loss: 3761.1428 - val_mae: 49.7140 - val_r2_keras: -1.0850e+00 - 574ms/epoch - 7ms/step\n",
            "Epoch 29/30\n",
            "84/84 - 1s - loss: 3900.4988 - mae: 50.3790 - r2_keras: -2.8156e-02 - val_loss: 3748.0322 - val_mae: 49.7025 - val_r2_keras: -1.1132e+00 - 560ms/epoch - 7ms/step\n",
            "Epoch 30/30\n",
            "84/84 - 1s - loss: 3892.3579 - mae: 50.3517 - r2_keras: -2.6958e-02 - val_loss: 3738.2173 - val_mae: 49.7010 - val_r2_keras: -1.1389e+00 - 614ms/epoch - 7ms/step\n",
            "dict_keys(['loss', 'mae', 'r2_keras', 'val_loss', 'val_mae', 'val_r2_keras'])\n"
          ]
        }
      ],
      "source": [
        "def r2_keras(y_true, y_pred):\n",
        "    \"\"\"Coefficient of Determination\n",
        "    \"\"\"\n",
        "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=nb_out))\n",
        "model.add(Activation(\"linear\"))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae',r2_keras])\n",
        "print(model.summary())\n",
        "\n",
        "# fit the network\n",
        "history = model.fit(seq_array, label_array, epochs=30, batch_size=200, validation_split=0.05, verbose=2,)\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDrp7F6Fn-3p",
        "outputId": "0f855b8b-a34b-41ae-f394-a5d11f427ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# We pick the last sequence for each id in the test data\n",
        "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:]\n",
        "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "\n",
        "y_pred_test = model.predict(seq_array_test_last)\n",
        "\n",
        "test_set = pd.DataFrame(y_pred_test, columns=['RUL'])\n",
        "test_set.index = test_set.index+1\n",
        "test_set.to_csv('my_submission.csv', index_label='id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rykyP6MmBBwS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import LSTM, Dense, Bidirectional\n",
        "import keras\n",
        "import seaborn as sns\n",
        "import keras.backend as K\n",
        "#from keras.layers.core import Activation\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Activation\n",
        "os.getcwd()\n",
        "# read training data - It is the aircraft engine run-to-failure data.\n",
        "train_df = pd.read_csv(r'./train.csv')\n",
        "print('viwe the data shape', train_df.shape)\n",
        "train_df.head()\n",
        "# read test data - It is the aircraft engine operating data without failure events recorded.\n",
        "test_df = pd.read_csv(r'./test.csv')\n",
        "print('viwe the data shape', test_df.shape)\n",
        "test_df.head()\n",
        "sequence_length = 30\n",
        "# function to reshape features into (samples, time steps, features)\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # for one id I put all the rows in a single matrix\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # Iterate over two lists in parallel.\n",
        "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
        "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
        "    # 0 50 -> from row 0 to row 50\n",
        "    # 1 51 -> from row 1 to row 51\n",
        "    # 2 52 -> from row 2 to row 52\n",
        "    # ...\n",
        "    # 111 191 -> from row 111 to 191\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "\n",
        "# pick the feature columns\n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['setting'+ str(i) for i in range(1,4)]\n",
        "sequence_cols.extend(sensor_cols)\n",
        "\n",
        "# generator for the sequences\n",
        "# transform each id of the train dataset in a sequence\n",
        "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols))\n",
        "           for id in train_df['id'].unique())\n",
        "\n",
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "print(seq_array.shape)\n",
        "\n",
        "# function to generate labels\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # For one id I put all the labels in a single matrix.\n",
        "    # For example:\n",
        "    # [[1]\n",
        "    # [4]\n",
        "    # [1]\n",
        "    # [5]\n",
        "    # [9]\n",
        "    # ...\n",
        "    # [200]]\n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # I have to remove the first seq_length labels\n",
        "    # because for one id the first sequence of seq_length size have as target\n",
        "    # the last label (the previus ones are discarded).\n",
        "    # All the next id's sequences will have associated step by step one label as target.\n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "# generate labels\n",
        "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL'])\n",
        "             for id in train_df['id'].unique()]\n",
        "\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "label_array.shape\n",
        "def r2_keras(y_true, y_pred):\n",
        "    \"\"\"Coefficient of Determination\n",
        "    \"\"\"\n",
        "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=nb_out))\n",
        "model.add(Activation(\"linear\"))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae',r2_keras])\n",
        "print(model.summary())\n",
        "\n",
        "# fit the network\n",
        "history = model.fit(seq_array, label_array, epochs=30, batch_size=200, validation_split=0.05, verbose=2,)\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# We pick the last sequence for each id in the test data\n",
        "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:]\n",
        "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "\n",
        "y_pred_test = model.predict(seq_array_test_last)\n",
        "\n",
        "test_set = pd.DataFrame(y_pred_test, columns=['RUL'])\n",
        "test_set.index = test_set.index+1\n",
        "test_set.to_csv('my_submission.csv', index_label='id')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
        "from keras.layers import Activation\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 讀取訓練數據和測試數據\n",
        "train_df = pd.read_csv(r'./train.csv')\n",
        "test_df = pd.read_csv(r'./test.csv')\n",
        "\n",
        "sequence_length = 30\n",
        "\n",
        "# 特徵列選擇\n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "setting_cols = ['setting'+ str(i) for i in range(1,4)]\n",
        "sequence_cols = setting_cols + sensor_cols\n",
        "\n",
        "# 生成序列的函數\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "\n",
        "# 生成標籤的函數\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "# 生成訓練數據和標籤\n",
        "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) for id in train_df['id'].unique())\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL']) for id in train_df['id'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "\n",
        "# 定義R2 Keras回歸指標\n",
        "def r2_keras(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
        "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
        "\n",
        "# 建立模型\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True), input_shape=(sequence_length, nb_features)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(units=50, return_sequences=False)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(units=nb_out))\n",
        "model.add(Activation(\"linear\"))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', r2_keras])\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit(seq_array, label_array, epochs=100, batch_size=100, validation_split=0.05, verbose=2)\n",
        "\n",
        "# 預測測試集\n",
        "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "y_pred_test = model.predict(seq_array_test_last)\n",
        "\n",
        "# 儲存預測結果\n",
        "test_set = pd.DataFrame(y_pred_test, columns=['RUL'])\n",
        "test_set.index = test_set.index+1\n",
        "test_set.to_csv('my_submission.csv', index_label='id')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qu2Tjt3PSFv",
        "outputId": "62a1ac0e-f3ec-4c62-c637-16eb78fcda7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "168/168 - 9s - loss: 5656.4126 - mae: 58.8917 - r2_keras: -4.9257e-01 - val_loss: 3711.9014 - val_mae: 49.9624 - val_r2_keras: -2.6007e+00 - 9s/epoch - 56ms/step\n",
            "Epoch 2/100\n",
            "168/168 - 2s - loss: 3841.3154 - mae: 50.5358 - r2_keras: -1.8239e-02 - val_loss: 3710.5085 - val_mae: 49.8828 - val_r2_keras: -2.5968e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 3/100\n",
            "168/168 - 2s - loss: 3829.9761 - mae: 50.4459 - r2_keras: -1.5410e-02 - val_loss: 3711.1377 - val_mae: 49.9326 - val_r2_keras: -2.5991e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 4/100\n",
            "168/168 - 2s - loss: 3835.3921 - mae: 50.4519 - r2_keras: -1.7268e-02 - val_loss: 3715.5613 - val_mae: 50.0509 - val_r2_keras: -2.6065e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 5/100\n",
            "168/168 - 2s - loss: 3830.0483 - mae: 50.4439 - r2_keras: -1.7133e-02 - val_loss: 3712.6995 - val_mae: 49.7972 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 6/100\n",
            "168/168 - 2s - loss: 3839.7117 - mae: 50.5125 - r2_keras: -1.7375e-02 - val_loss: 3719.4778 - val_mae: 50.1203 - val_r2_keras: -2.6118e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 7/100\n",
            "168/168 - 2s - loss: 3835.8521 - mae: 50.4535 - r2_keras: -1.6506e-02 - val_loss: 3721.5381 - val_mae: 49.7298 - val_r2_keras: -2.5993e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 8/100\n",
            "168/168 - 2s - loss: 3838.2144 - mae: 50.5237 - r2_keras: -1.7991e-02 - val_loss: 3712.9756 - val_mae: 49.7934 - val_r2_keras: -2.5954e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 9/100\n",
            "168/168 - 2s - loss: 3828.4233 - mae: 50.3991 - r2_keras: -1.4504e-02 - val_loss: 3710.6287 - val_mae: 49.8567 - val_r2_keras: -2.5960e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 10/100\n",
            "168/168 - 2s - loss: 3836.1936 - mae: 50.4916 - r2_keras: -1.9358e-02 - val_loss: 3714.0557 - val_mae: 50.0187 - val_r2_keras: -2.6043e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 11/100\n",
            "168/168 - 2s - loss: 3844.2666 - mae: 50.4922 - r2_keras: -1.9799e-02 - val_loss: 3710.8164 - val_mae: 49.8455 - val_r2_keras: -2.5957e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 12/100\n",
            "168/168 - 2s - loss: 3839.8804 - mae: 50.5276 - r2_keras: -1.8274e-02 - val_loss: 3711.0544 - val_mae: 49.9284 - val_r2_keras: -2.5989e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 13/100\n",
            "168/168 - 2s - loss: 3833.5610 - mae: 50.4322 - r2_keras: -1.7923e-02 - val_loss: 3723.1543 - val_mae: 50.1763 - val_r2_keras: -2.6165e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 14/100\n",
            "168/168 - 2s - loss: 3840.7820 - mae: 50.4720 - r2_keras: -1.7824e-02 - val_loss: 3711.6765 - val_mae: 49.8169 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 15/100\n",
            "168/168 - 2s - loss: 3838.5969 - mae: 50.4820 - r2_keras: -1.7737e-02 - val_loss: 3719.5088 - val_mae: 50.1209 - val_r2_keras: -2.6118e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 16/100\n",
            "168/168 - 2s - loss: 3838.5002 - mae: 50.5131 - r2_keras: -1.6258e-02 - val_loss: 3711.3708 - val_mae: 49.8252 - val_r2_keras: -2.5954e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 17/100\n",
            "168/168 - 2s - loss: 3840.3796 - mae: 50.4974 - r2_keras: -1.8299e-02 - val_loss: 3712.1877 - val_mae: 49.8052 - val_r2_keras: -2.5953e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 18/100\n",
            "168/168 - 2s - loss: 3840.7610 - mae: 50.5065 - r2_keras: -2.1205e-02 - val_loss: 3714.3145 - val_mae: 50.0247 - val_r2_keras: -2.6047e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 19/100\n",
            "168/168 - 2s - loss: 3834.9812 - mae: 50.4737 - r2_keras: -1.7930e-02 - val_loss: 3710.5234 - val_mae: 49.8881 - val_r2_keras: -2.5970e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 20/100\n",
            "168/168 - 2s - loss: 3828.0552 - mae: 50.3737 - r2_keras: -1.7263e-02 - val_loss: 3712.4324 - val_mae: 49.9783 - val_r2_keras: -2.6016e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 21/100\n",
            "168/168 - 2s - loss: 3835.9380 - mae: 50.4679 - r2_keras: -1.8313e-02 - val_loss: 3721.8499 - val_mae: 50.1575 - val_r2_keras: -2.6148e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 22/100\n",
            "168/168 - 2s - loss: 3831.2615 - mae: 50.4121 - r2_keras: -1.6207e-02 - val_loss: 3710.5183 - val_mae: 49.8717 - val_r2_keras: -2.5964e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 23/100\n",
            "168/168 - 2s - loss: 3835.3372 - mae: 50.4811 - r2_keras: -1.8154e-02 - val_loss: 3717.1211 - val_mae: 50.0795 - val_r2_keras: -2.6087e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 24/100\n",
            "168/168 - 2s - loss: 3842.6912 - mae: 50.5124 - r2_keras: -1.9442e-02 - val_loss: 3711.0408 - val_mae: 49.8360 - val_r2_keras: -2.5955e+00 - 2s/epoch - 15ms/step\n",
            "Epoch 25/100\n",
            "168/168 - 2s - loss: 3837.9224 - mae: 50.5147 - r2_keras: -1.8083e-02 - val_loss: 3711.4280 - val_mae: 49.8236 - val_r2_keras: -2.5954e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 26/100\n",
            "168/168 - 2s - loss: 3836.4587 - mae: 50.4797 - r2_keras: -1.5572e-02 - val_loss: 3724.2644 - val_mae: 49.7218 - val_r2_keras: -2.6010e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 27/100\n",
            "168/168 - 2s - loss: 3840.1548 - mae: 50.5232 - r2_keras: -2.2107e-02 - val_loss: 3729.8218 - val_mae: 49.7089 - val_r2_keras: -2.6045e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 28/100\n",
            "168/168 - 2s - loss: 3838.7976 - mae: 50.4595 - r2_keras: -1.8177e-02 - val_loss: 3712.1780 - val_mae: 49.9710 - val_r2_keras: -2.6012e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 29/100\n",
            "168/168 - 2s - loss: 3843.9871 - mae: 50.5167 - r2_keras: -1.9316e-02 - val_loss: 3711.8599 - val_mae: 49.9611 - val_r2_keras: -2.6006e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 30/100\n",
            "168/168 - 2s - loss: 3838.1023 - mae: 50.5324 - r2_keras: -2.0517e-02 - val_loss: 3710.6033 - val_mae: 49.8588 - val_r2_keras: -2.5961e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 31/100\n",
            "168/168 - 2s - loss: 3837.2817 - mae: 50.4516 - r2_keras: -1.7671e-02 - val_loss: 3710.7080 - val_mae: 49.9089 - val_r2_keras: -2.5979e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 32/100\n",
            "168/168 - 2s - loss: 3836.2390 - mae: 50.4690 - r2_keras: -1.7858e-02 - val_loss: 3710.6985 - val_mae: 49.9081 - val_r2_keras: -2.5979e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 33/100\n",
            "168/168 - 2s - loss: 3833.9424 - mae: 50.3976 - r2_keras: -1.6946e-02 - val_loss: 3721.7971 - val_mae: 50.1567 - val_r2_keras: -2.6148e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 34/100\n",
            "168/168 - 2s - loss: 3839.9475 - mae: 50.5063 - r2_keras: -1.6537e-02 - val_loss: 3710.9421 - val_mae: 49.8399 - val_r2_keras: -2.5956e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 35/100\n",
            "168/168 - 2s - loss: 3837.3784 - mae: 50.5157 - r2_keras: -1.7247e-02 - val_loss: 3713.8501 - val_mae: 49.7823 - val_r2_keras: -2.5956e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 36/100\n",
            "168/168 - 2s - loss: 3841.3838 - mae: 50.5013 - r2_keras: -1.9961e-02 - val_loss: 3718.1519 - val_mae: 49.7472 - val_r2_keras: -2.5975e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 37/100\n",
            "168/168 - 2s - loss: 3827.5044 - mae: 50.3722 - r2_keras: -1.5842e-02 - val_loss: 3717.8525 - val_mae: 50.0919 - val_r2_keras: -2.6097e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 38/100\n",
            "168/168 - 2s - loss: 3836.7871 - mae: 50.4654 - r2_keras: -1.8256e-02 - val_loss: 3710.5715 - val_mae: 49.8961 - val_r2_keras: -2.5973e+00 - 2s/epoch - 13ms/step\n",
            "Epoch 39/100\n",
            "168/168 - 2s - loss: 3832.6086 - mae: 50.4758 - r2_keras: -1.6080e-02 - val_loss: 3719.7148 - val_mae: 49.7386 - val_r2_keras: -2.5983e+00 - 2s/epoch - 13ms/step\n",
            "Epoch 40/100\n",
            "168/168 - 2s - loss: 3834.5789 - mae: 50.4733 - r2_keras: -1.8000e-02 - val_loss: 3710.5613 - val_mae: 49.8948 - val_r2_keras: -2.5973e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 41/100\n",
            "168/168 - 2s - loss: 3830.5276 - mae: 50.4730 - r2_keras: -1.4525e-02 - val_loss: 3713.7664 - val_mae: 49.7833 - val_r2_keras: -2.5956e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 42/100\n",
            "168/168 - 2s - loss: 3835.8777 - mae: 50.4548 - r2_keras: -1.4099e-02 - val_loss: 3714.0615 - val_mae: 50.0188 - val_r2_keras: -2.6043e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 43/100\n",
            "168/168 - 2s - loss: 3836.7021 - mae: 50.4406 - r2_keras: -1.9372e-02 - val_loss: 3711.5278 - val_mae: 49.8208 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 44/100\n",
            "168/168 - 2s - loss: 3823.5264 - mae: 50.3958 - r2_keras: -1.2769e-02 - val_loss: 3717.8171 - val_mae: 49.7491 - val_r2_keras: -2.5973e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 45/100\n",
            "168/168 - 2s - loss: 3833.7002 - mae: 50.4598 - r2_keras: -1.9252e-02 - val_loss: 3712.2444 - val_mae: 49.9730 - val_r2_keras: -2.6013e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 46/100\n",
            "168/168 - 2s - loss: 3828.7639 - mae: 50.3705 - r2_keras: -1.6134e-02 - val_loss: 3722.1758 - val_mae: 50.1623 - val_r2_keras: -2.6153e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 47/100\n",
            "168/168 - 2s - loss: 3834.0220 - mae: 50.4431 - r2_keras: -1.5025e-02 - val_loss: 3726.8669 - val_mae: 50.2290 - val_r2_keras: -2.6210e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 48/100\n",
            "168/168 - 2s - loss: 3835.0129 - mae: 50.4725 - r2_keras: -1.8887e-02 - val_loss: 3710.5066 - val_mae: 49.8812 - val_r2_keras: -2.5968e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 49/100\n",
            "168/168 - 2s - loss: 3830.1355 - mae: 50.4547 - r2_keras: -1.6278e-02 - val_loss: 3711.1936 - val_mae: 49.9353 - val_r2_keras: -2.5992e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 50/100\n",
            "168/168 - 2s - loss: 3836.6204 - mae: 50.4958 - r2_keras: -1.9438e-02 - val_loss: 3710.5823 - val_mae: 49.8610 - val_r2_keras: -2.5961e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 51/100\n",
            "168/168 - 2s - loss: 3833.7273 - mae: 50.4542 - r2_keras: -1.6109e-02 - val_loss: 3710.7449 - val_mae: 49.8492 - val_r2_keras: -2.5958e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 52/100\n",
            "168/168 - 2s - loss: 3831.4092 - mae: 50.4333 - r2_keras: -1.3997e-02 - val_loss: 3715.6675 - val_mae: 49.7632 - val_r2_keras: -2.5963e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 53/100\n",
            "168/168 - 3s - loss: 3842.8413 - mae: 50.4931 - r2_keras: -1.8387e-02 - val_loss: 3710.5527 - val_mae: 49.8936 - val_r2_keras: -2.5972e+00 - 3s/epoch - 18ms/step\n",
            "Epoch 54/100\n",
            "168/168 - 2s - loss: 3832.9287 - mae: 50.4589 - r2_keras: -1.5553e-02 - val_loss: 3744.3875 - val_mae: 49.7019 - val_r2_keras: -2.6147e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 55/100\n",
            "168/168 - 2s - loss: 3835.5156 - mae: 50.4444 - r2_keras: -1.6061e-02 - val_loss: 3711.4807 - val_mae: 49.8221 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 56/100\n",
            "168/168 - 2s - loss: 3834.7961 - mae: 50.4770 - r2_keras: -1.7586e-02 - val_loss: 3711.7319 - val_mae: 49.8156 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 57/100\n",
            "168/168 - 2s - loss: 3837.1143 - mae: 50.4956 - r2_keras: -1.7304e-02 - val_loss: 3713.7817 - val_mae: 50.0122 - val_r2_keras: -2.6038e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 58/100\n",
            "168/168 - 2s - loss: 3839.1816 - mae: 50.4830 - r2_keras: -1.8567e-02 - val_loss: 3717.0522 - val_mae: 50.0783 - val_r2_keras: -2.6086e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 59/100\n",
            "168/168 - 2s - loss: 3838.1890 - mae: 50.5061 - r2_keras: -1.8900e-02 - val_loss: 3722.4087 - val_mae: 49.7271 - val_r2_keras: -2.5998e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 60/100\n",
            "168/168 - 2s - loss: 3835.5161 - mae: 50.4900 - r2_keras: -1.6424e-02 - val_loss: 3711.5984 - val_mae: 49.9519 - val_r2_keras: -2.6001e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 61/100\n",
            "168/168 - 2s - loss: 3842.4507 - mae: 50.4683 - r2_keras: -1.7702e-02 - val_loss: 3711.0229 - val_mae: 49.8367 - val_r2_keras: -2.5955e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 62/100\n",
            "168/168 - 2s - loss: 3831.2603 - mae: 50.4235 - r2_keras: -1.7938e-02 - val_loss: 3711.7046 - val_mae: 49.8162 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 63/100\n",
            "168/168 - 2s - loss: 3836.3394 - mae: 50.4375 - r2_keras: -1.7120e-02 - val_loss: 3715.0928 - val_mae: 50.0415 - val_r2_keras: -2.6058e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 64/100\n",
            "168/168 - 2s - loss: 3841.0811 - mae: 50.5567 - r2_keras: -1.8041e-02 - val_loss: 3715.4609 - val_mae: 49.7652 - val_r2_keras: -2.5962e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 65/100\n",
            "168/168 - 2s - loss: 3829.6543 - mae: 50.3861 - r2_keras: -1.6642e-02 - val_loss: 3714.6919 - val_mae: 49.7729 - val_r2_keras: -2.5959e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 66/100\n",
            "168/168 - 2s - loss: 3836.8018 - mae: 50.4587 - r2_keras: -1.8341e-02 - val_loss: 3710.6106 - val_mae: 49.8582 - val_r2_keras: -2.5960e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 67/100\n",
            "168/168 - 2s - loss: 3831.1274 - mae: 50.4279 - r2_keras: -1.4800e-02 - val_loss: 3714.8440 - val_mae: 50.0363 - val_r2_keras: -2.6054e+00 - 2s/epoch - 13ms/step\n",
            "Epoch 68/100\n",
            "168/168 - 2s - loss: 3843.7368 - mae: 50.5614 - r2_keras: -2.1091e-02 - val_loss: 3712.2549 - val_mae: 49.9733 - val_r2_keras: -2.6013e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 69/100\n",
            "168/168 - 2s - loss: 3832.6504 - mae: 50.4316 - r2_keras: -1.5760e-02 - val_loss: 3735.9272 - val_mae: 50.3437 - val_r2_keras: -2.6317e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 70/100\n",
            "168/168 - 2s - loss: 3838.6714 - mae: 50.4794 - r2_keras: -1.9975e-02 - val_loss: 3710.8850 - val_mae: 49.8423 - val_r2_keras: -2.5956e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 71/100\n",
            "168/168 - 2s - loss: 3833.1016 - mae: 50.4383 - r2_keras: -1.5194e-02 - val_loss: 3710.5222 - val_mae: 49.8877 - val_r2_keras: -2.5970e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 72/100\n",
            "168/168 - 2s - loss: 3828.6301 - mae: 50.3840 - r2_keras: -1.5175e-02 - val_loss: 3711.7546 - val_mae: 49.8150 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 73/100\n",
            "168/168 - 2s - loss: 3845.8459 - mae: 50.5351 - r2_keras: -1.8705e-02 - val_loss: 3716.7673 - val_mae: 49.7555 - val_r2_keras: -2.5968e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 74/100\n",
            "168/168 - 2s - loss: 3842.1758 - mae: 50.4850 - r2_keras: -1.9441e-02 - val_loss: 3711.2739 - val_mae: 49.9389 - val_r2_keras: -2.5994e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 75/100\n",
            "168/168 - 2s - loss: 3840.2490 - mae: 50.5027 - r2_keras: -1.7397e-02 - val_loss: 3716.1282 - val_mae: 49.7597 - val_r2_keras: -2.5965e+00 - 2s/epoch - 15ms/step\n",
            "Epoch 76/100\n",
            "168/168 - 2s - loss: 3836.7629 - mae: 50.4687 - r2_keras: -1.8067e-02 - val_loss: 3716.7881 - val_mae: 50.0737 - val_r2_keras: -2.6082e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 77/100\n",
            "168/168 - 2s - loss: 3833.2390 - mae: 50.4315 - r2_keras: -1.6004e-02 - val_loss: 3714.3079 - val_mae: 49.7770 - val_r2_keras: -2.5958e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 78/100\n",
            "168/168 - 2s - loss: 3831.8862 - mae: 50.4237 - r2_keras: -1.4033e-02 - val_loss: 3722.6501 - val_mae: 50.1692 - val_r2_keras: -2.6159e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 79/100\n",
            "168/168 - 2s - loss: 3831.1877 - mae: 50.4230 - r2_keras: -1.5557e-02 - val_loss: 3710.6809 - val_mae: 49.9068 - val_r2_keras: -2.5978e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 80/100\n",
            "168/168 - 2s - loss: 3842.2451 - mae: 50.5225 - r2_keras: -1.8643e-02 - val_loss: 3714.8950 - val_mae: 50.0374 - val_r2_keras: -2.6055e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 81/100\n",
            "168/168 - 2s - loss: 3835.8533 - mae: 50.4805 - r2_keras: -1.9405e-02 - val_loss: 3711.8457 - val_mae: 49.8128 - val_r2_keras: -2.5953e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 82/100\n",
            "168/168 - 2s - loss: 3836.4795 - mae: 50.4477 - r2_keras: -1.5141e-02 - val_loss: 3714.3901 - val_mae: 50.0264 - val_r2_keras: -2.6048e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 83/100\n",
            "168/168 - 2s - loss: 3835.6509 - mae: 50.4882 - r2_keras: -1.6805e-02 - val_loss: 3716.2307 - val_mae: 50.0637 - val_r2_keras: -2.6074e+00 - 2s/epoch - 12ms/step\n",
            "Epoch 84/100\n",
            "168/168 - 2s - loss: 3844.9102 - mae: 50.5569 - r2_keras: -2.2292e-02 - val_loss: 3712.2478 - val_mae: 49.8042 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 85/100\n",
            "168/168 - 2s - loss: 3832.7034 - mae: 50.3964 - r2_keras: -1.5900e-02 - val_loss: 3714.2517 - val_mae: 49.7777 - val_r2_keras: -2.5957e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 86/100\n",
            "168/168 - 2s - loss: 3832.9458 - mae: 50.4864 - r2_keras: -1.6303e-02 - val_loss: 3721.6516 - val_mae: 49.7294 - val_r2_keras: -2.5994e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 87/100\n",
            "168/168 - 2s - loss: 3837.9990 - mae: 50.4659 - r2_keras: -1.6999e-02 - val_loss: 3710.9976 - val_mae: 49.9254 - val_r2_keras: -2.5987e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 88/100\n",
            "168/168 - 2s - loss: 3841.3652 - mae: 50.5616 - r2_keras: -1.7076e-02 - val_loss: 3711.8589 - val_mae: 49.9610 - val_r2_keras: -2.6006e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 89/100\n",
            "168/168 - 2s - loss: 3836.8879 - mae: 50.4773 - r2_keras: -1.8757e-02 - val_loss: 3710.8579 - val_mae: 49.9183 - val_r2_keras: -2.5984e+00 - 2s/epoch - 14ms/step\n",
            "Epoch 90/100\n",
            "168/168 - 4s - loss: 3835.5806 - mae: 50.5020 - r2_keras: -1.9015e-02 - val_loss: 3710.5701 - val_mae: 49.8626 - val_r2_keras: -2.5962e+00 - 4s/epoch - 21ms/step\n",
            "Epoch 91/100\n",
            "168/168 - 3s - loss: 3825.8257 - mae: 50.4052 - r2_keras: -1.5610e-02 - val_loss: 3711.2070 - val_mae: 49.9359 - val_r2_keras: -2.5992e+00 - 3s/epoch - 16ms/step\n",
            "Epoch 92/100\n",
            "168/168 - 2s - loss: 3836.5098 - mae: 50.4771 - r2_keras: -1.7074e-02 - val_loss: 3720.8081 - val_mae: 49.7331 - val_r2_keras: -2.5989e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 93/100\n",
            "168/168 - 2s - loss: 3838.1033 - mae: 50.4731 - r2_keras: -1.8728e-02 - val_loss: 3718.2271 - val_mae: 50.0987 - val_r2_keras: -2.6102e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 94/100\n",
            "168/168 - 2s - loss: 3836.7151 - mae: 50.4740 - r2_keras: -1.6081e-02 - val_loss: 3712.6335 - val_mae: 49.9838 - val_r2_keras: -2.6020e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 95/100\n",
            "168/168 - 2s - loss: 3830.8140 - mae: 50.4106 - r2_keras: -1.6809e-02 - val_loss: 3712.2866 - val_mae: 49.8036 - val_r2_keras: -2.5953e+00 - 2s/epoch - 13ms/step\n",
            "Epoch 96/100\n",
            "168/168 - 2s - loss: 3835.1436 - mae: 50.4358 - r2_keras: -1.6527e-02 - val_loss: 3711.0193 - val_mae: 49.9266 - val_r2_keras: -2.5988e+00 - 2s/epoch - 13ms/step\n",
            "Epoch 97/100\n",
            "168/168 - 2s - loss: 3837.0474 - mae: 50.4751 - r2_keras: -1.6107e-02 - val_loss: 3714.7905 - val_mae: 50.0351 - val_r2_keras: -2.6054e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 98/100\n",
            "168/168 - 2s - loss: 3829.1313 - mae: 50.4156 - r2_keras: -1.4413e-02 - val_loss: 3713.4685 - val_mae: 49.7869 - val_r2_keras: -2.5955e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 99/100\n",
            "168/168 - 2s - loss: 3831.1636 - mae: 50.4443 - r2_keras: -1.5453e-02 - val_loss: 3712.0198 - val_mae: 49.8088 - val_r2_keras: -2.5953e+00 - 2s/epoch - 10ms/step\n",
            "Epoch 100/100\n",
            "168/168 - 2s - loss: 3833.1318 - mae: 50.4626 - r2_keras: -1.6785e-02 - val_loss: 3710.5500 - val_mae: 49.8932 - val_r2_keras: -2.5972e+00 - 2s/epoch - 10ms/step\n",
            "4/4 [==============================] - 1s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
        "from keras.layers import Activation\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 讀取並預處理數據\n",
        "train_df = pd.read_csv(r'./train.csv')\n",
        "test_df = pd.read_csv(r'./test.csv')\n",
        "sequence_length = 30\n",
        "\n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "setting_cols = ['setting' + str(i) for i in range(1,4)]\n",
        "sequence_cols = setting_cols + sensor_cols\n",
        "\n",
        "# 數據標準化\n",
        "scaler = StandardScaler()\n",
        "train_df[sequence_cols] = scaler.fit_transform(train_df[sequence_cols])\n",
        "test_df[sequence_cols] = scaler.transform(test_df[sequence_cols])\n",
        "\n",
        "# 生成序列和標籤\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) for id in train_df['id'].unique())\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL']) for id in train_df['id'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "\n",
        "# 模型建立\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(sequence_length, nb_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(units=50, return_sequences=False)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dense(units=nb_out))\n",
        "model.add(Activation(\"linear\"))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', r2_keras])\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit(seq_array, label_array, epochs=110, batch_size=200, validation_split=0.1, verbose=2)\n",
        "\n",
        "# 預測並保存結果\n",
        "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "y_pred_test = model.predict(seq_array_test_last)\n",
        "test_set = pd.DataFrame(y_pred_test, columns=['RUL'])\n",
        "test_set.index = test_set.index+1\n",
        "test_set.to_csv('my_submission.csv', index_label='id')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq-t02DUfnlx",
        "outputId": "2a9f7ae8-a092-4e6f-96a7-bb0fee8f828f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n",
            "80/80 - 16s - loss: 7006.2744 - mae: 65.3536 - r2_keras: -9.2474e-01 - val_loss: 5208.1948 - val_mae: 57.7794 - val_r2_keras: -3.2626e-01 - 16s/epoch - 197ms/step\n",
            "Epoch 2/110\n",
            "80/80 - 1s - loss: 2536.2534 - mae: 37.9476 - r2_keras: 0.3014 - val_loss: 2254.9302 - val_mae: 35.2496 - val_r2_keras: 0.4300 - 864ms/epoch - 11ms/step\n",
            "Epoch 3/110\n",
            "80/80 - 1s - loss: 1320.7590 - mae: 25.6220 - r2_keras: 0.6394 - val_loss: 1825.1820 - val_mae: 30.6266 - val_r2_keras: 0.5649 - 799ms/epoch - 10ms/step\n",
            "Epoch 4/110\n",
            "80/80 - 1s - loss: 1019.8317 - mae: 21.6144 - r2_keras: 0.7212 - val_loss: 1712.1676 - val_mae: 29.6648 - val_r2_keras: 0.3981 - 765ms/epoch - 10ms/step\n",
            "Epoch 5/110\n",
            "80/80 - 1s - loss: 920.1761 - mae: 20.3677 - r2_keras: 0.7477 - val_loss: 1752.0417 - val_mae: 28.0359 - val_r2_keras: 0.5534 - 774ms/epoch - 10ms/step\n",
            "Epoch 6/110\n",
            "80/80 - 1s - loss: 781.9423 - mae: 19.0232 - r2_keras: 0.7852 - val_loss: 1598.9059 - val_mae: 27.4004 - val_r2_keras: 0.5275 - 773ms/epoch - 10ms/step\n",
            "Epoch 7/110\n",
            "80/80 - 1s - loss: 729.1259 - mae: 18.3116 - r2_keras: 0.7995 - val_loss: 1804.6206 - val_mae: 27.7659 - val_r2_keras: 0.4827 - 770ms/epoch - 10ms/step\n",
            "Epoch 8/110\n",
            "80/80 - 1s - loss: 682.4125 - mae: 17.7689 - r2_keras: 0.8115 - val_loss: 2182.0999 - val_mae: 31.6823 - val_r2_keras: 0.4518 - 781ms/epoch - 10ms/step\n",
            "Epoch 9/110\n",
            "80/80 - 1s - loss: 611.5405 - mae: 16.8539 - r2_keras: 0.8326 - val_loss: 2074.9597 - val_mae: 29.1363 - val_r2_keras: 0.4792 - 762ms/epoch - 10ms/step\n",
            "Epoch 10/110\n",
            "80/80 - 1s - loss: 510.3973 - mae: 15.3780 - r2_keras: 0.8586 - val_loss: 2233.9861 - val_mae: 31.1445 - val_r2_keras: 0.4286 - 773ms/epoch - 10ms/step\n",
            "Epoch 11/110\n",
            "80/80 - 1s - loss: 504.6338 - mae: 15.3836 - r2_keras: 0.8611 - val_loss: 2156.6201 - val_mae: 29.8365 - val_r2_keras: 0.2587 - 773ms/epoch - 10ms/step\n",
            "Epoch 12/110\n",
            "80/80 - 1s - loss: 511.2915 - mae: 15.5515 - r2_keras: 0.8590 - val_loss: 2182.4150 - val_mae: 30.2665 - val_r2_keras: 0.2607 - 785ms/epoch - 10ms/step\n",
            "Epoch 13/110\n",
            "80/80 - 1s - loss: 401.5247 - mae: 13.9357 - r2_keras: 0.8894 - val_loss: 2232.8948 - val_mae: 30.5527 - val_r2_keras: 0.3700 - 754ms/epoch - 9ms/step\n",
            "Epoch 14/110\n",
            "80/80 - 1s - loss: 398.0841 - mae: 13.6676 - r2_keras: 0.8905 - val_loss: 2289.4944 - val_mae: 30.3002 - val_r2_keras: 0.3600 - 911ms/epoch - 11ms/step\n",
            "Epoch 15/110\n",
            "80/80 - 1s - loss: 343.6843 - mae: 12.7947 - r2_keras: 0.9049 - val_loss: 2249.2251 - val_mae: 30.3789 - val_r2_keras: 0.3062 - 1s/epoch - 13ms/step\n",
            "Epoch 16/110\n",
            "80/80 - 1s - loss: 328.2106 - mae: 12.4114 - r2_keras: 0.9087 - val_loss: 2114.9617 - val_mae: 29.8802 - val_r2_keras: 0.4333 - 1s/epoch - 15ms/step\n",
            "Epoch 17/110\n",
            "80/80 - 1s - loss: 324.1081 - mae: 12.4377 - r2_keras: 0.9108 - val_loss: 2495.5820 - val_mae: 32.1229 - val_r2_keras: 0.1667 - 1s/epoch - 14ms/step\n",
            "Epoch 18/110\n",
            "80/80 - 1s - loss: 288.0192 - mae: 11.6802 - r2_keras: 0.9201 - val_loss: 2312.4153 - val_mae: 31.0935 - val_r2_keras: 0.3044 - 823ms/epoch - 10ms/step\n",
            "Epoch 19/110\n",
            "80/80 - 1s - loss: 284.4008 - mae: 11.7459 - r2_keras: 0.9211 - val_loss: 2521.8167 - val_mae: 32.8849 - val_r2_keras: 0.1717 - 813ms/epoch - 10ms/step\n",
            "Epoch 20/110\n",
            "80/80 - 1s - loss: 261.9316 - mae: 11.1759 - r2_keras: 0.9271 - val_loss: 2303.8975 - val_mae: 30.8355 - val_r2_keras: 0.3180 - 788ms/epoch - 10ms/step\n",
            "Epoch 21/110\n",
            "80/80 - 1s - loss: 232.4294 - mae: 10.6549 - r2_keras: 0.9358 - val_loss: 2266.8647 - val_mae: 30.7834 - val_r2_keras: 0.2923 - 848ms/epoch - 11ms/step\n",
            "Epoch 22/110\n",
            "80/80 - 1s - loss: 223.1516 - mae: 10.4103 - r2_keras: 0.9383 - val_loss: 2247.0190 - val_mae: 31.5204 - val_r2_keras: 0.1774 - 812ms/epoch - 10ms/step\n",
            "Epoch 23/110\n",
            "80/80 - 1s - loss: 212.2092 - mae: 10.1973 - r2_keras: 0.9415 - val_loss: 2252.2908 - val_mae: 30.7219 - val_r2_keras: 0.2600 - 849ms/epoch - 11ms/step\n",
            "Epoch 24/110\n",
            "80/80 - 1s - loss: 188.3841 - mae: 9.7032 - r2_keras: 0.9481 - val_loss: 2343.1145 - val_mae: 31.4448 - val_r2_keras: 0.3532 - 826ms/epoch - 10ms/step\n",
            "Epoch 25/110\n",
            "80/80 - 1s - loss: 213.3396 - mae: 10.2886 - r2_keras: 0.9413 - val_loss: 2291.4844 - val_mae: 31.1460 - val_r2_keras: 0.2480 - 826ms/epoch - 10ms/step\n",
            "Epoch 26/110\n",
            "80/80 - 1s - loss: 162.2366 - mae: 9.0013 - r2_keras: 0.9549 - val_loss: 2310.3203 - val_mae: 32.0255 - val_r2_keras: 0.1071 - 811ms/epoch - 10ms/step\n",
            "Epoch 27/110\n",
            "80/80 - 1s - loss: 145.8920 - mae: 8.5932 - r2_keras: 0.9595 - val_loss: 2461.6272 - val_mae: 32.8037 - val_r2_keras: 0.0589 - 823ms/epoch - 10ms/step\n",
            "Epoch 28/110\n",
            "80/80 - 1s - loss: 164.1395 - mae: 8.9846 - r2_keras: 0.9547 - val_loss: 2399.3591 - val_mae: 32.1928 - val_r2_keras: 0.2217 - 802ms/epoch - 10ms/step\n",
            "Epoch 29/110\n",
            "80/80 - 1s - loss: 136.5488 - mae: 8.3759 - r2_keras: 0.9623 - val_loss: 2369.0518 - val_mae: 31.9046 - val_r2_keras: 0.2393 - 938ms/epoch - 12ms/step\n",
            "Epoch 30/110\n",
            "80/80 - 1s - loss: 133.6751 - mae: 8.2354 - r2_keras: 0.9631 - val_loss: 2193.2195 - val_mae: 31.3885 - val_r2_keras: 0.2548 - 1s/epoch - 15ms/step\n",
            "Epoch 31/110\n",
            "80/80 - 1s - loss: 120.3873 - mae: 7.8410 - r2_keras: 0.9668 - val_loss: 2499.4875 - val_mae: 32.7439 - val_r2_keras: 0.1692 - 1s/epoch - 14ms/step\n",
            "Epoch 32/110\n",
            "80/80 - 1s - loss: 112.9171 - mae: 7.6211 - r2_keras: 0.9687 - val_loss: 2505.4282 - val_mae: 32.1251 - val_r2_keras: 0.1833 - 1s/epoch - 13ms/step\n",
            "Epoch 33/110\n",
            "80/80 - 1s - loss: 113.3615 - mae: 7.6621 - r2_keras: 0.9685 - val_loss: 2328.5977 - val_mae: 31.7809 - val_r2_keras: 0.0910 - 803ms/epoch - 10ms/step\n",
            "Epoch 34/110\n",
            "80/80 - 1s - loss: 107.9683 - mae: 7.4900 - r2_keras: 0.9702 - val_loss: 2414.9011 - val_mae: 32.1639 - val_r2_keras: 0.1591 - 795ms/epoch - 10ms/step\n",
            "Epoch 35/110\n",
            "80/80 - 1s - loss: 95.4383 - mae: 7.0455 - r2_keras: 0.9737 - val_loss: 2411.9526 - val_mae: 32.4264 - val_r2_keras: 0.1715 - 837ms/epoch - 10ms/step\n",
            "Epoch 36/110\n",
            "80/80 - 1s - loss: 91.8480 - mae: 6.9322 - r2_keras: 0.9747 - val_loss: 2408.9705 - val_mae: 32.2230 - val_r2_keras: 0.2045 - 959ms/epoch - 12ms/step\n",
            "Epoch 37/110\n",
            "80/80 - 1s - loss: 95.6452 - mae: 7.0409 - r2_keras: 0.9734 - val_loss: 2547.1577 - val_mae: 32.9349 - val_r2_keras: 0.0762 - 880ms/epoch - 11ms/step\n",
            "Epoch 38/110\n",
            "80/80 - 1s - loss: 89.3670 - mae: 6.7963 - r2_keras: 0.9753 - val_loss: 2502.4451 - val_mae: 32.6502 - val_r2_keras: 0.1996 - 931ms/epoch - 12ms/step\n",
            "Epoch 39/110\n",
            "80/80 - 1s - loss: 93.0454 - mae: 6.9556 - r2_keras: 0.9741 - val_loss: 2489.5505 - val_mae: 32.2721 - val_r2_keras: 0.1513 - 989ms/epoch - 12ms/step\n",
            "Epoch 40/110\n",
            "80/80 - 1s - loss: 81.5559 - mae: 6.5500 - r2_keras: 0.9773 - val_loss: 2355.9131 - val_mae: 32.1448 - val_r2_keras: 0.1340 - 849ms/epoch - 11ms/step\n",
            "Epoch 41/110\n",
            "80/80 - 1s - loss: 84.7099 - mae: 6.6376 - r2_keras: 0.9767 - val_loss: 2616.6431 - val_mae: 33.1389 - val_r2_keras: 0.0169 - 840ms/epoch - 10ms/step\n",
            "Epoch 42/110\n",
            "80/80 - 1s - loss: 80.7720 - mae: 6.4673 - r2_keras: 0.9776 - val_loss: 2410.7563 - val_mae: 31.7899 - val_r2_keras: 0.2827 - 826ms/epoch - 10ms/step\n",
            "Epoch 43/110\n",
            "80/80 - 1s - loss: 73.4682 - mae: 6.1762 - r2_keras: 0.9796 - val_loss: 2545.6401 - val_mae: 32.7959 - val_r2_keras: 0.2003 - 789ms/epoch - 10ms/step\n",
            "Epoch 44/110\n",
            "80/80 - 1s - loss: 174.3490 - mae: 8.2652 - r2_keras: 0.9520 - val_loss: 2570.1985 - val_mae: 32.4539 - val_r2_keras: 0.1509 - 1s/epoch - 13ms/step\n",
            "Epoch 45/110\n",
            "80/80 - 1s - loss: 112.1452 - mae: 7.3963 - r2_keras: 0.9690 - val_loss: 2479.2002 - val_mae: 32.3019 - val_r2_keras: 0.0899 - 1s/epoch - 15ms/step\n",
            "Epoch 46/110\n",
            "80/80 - 1s - loss: 72.3252 - mae: 6.1432 - r2_keras: 0.9800 - val_loss: 2697.8669 - val_mae: 33.3118 - val_r2_keras: -7.7346e-02 - 1s/epoch - 14ms/step\n",
            "Epoch 47/110\n",
            "80/80 - 1s - loss: 67.1712 - mae: 5.8971 - r2_keras: 0.9814 - val_loss: 2571.9165 - val_mae: 32.7719 - val_r2_keras: 0.1311 - 915ms/epoch - 11ms/step\n",
            "Epoch 48/110\n",
            "80/80 - 1s - loss: 66.6988 - mae: 5.9005 - r2_keras: 0.9815 - val_loss: 2659.4177 - val_mae: 33.7839 - val_r2_keras: 0.0555 - 854ms/epoch - 11ms/step\n",
            "Epoch 49/110\n",
            "80/80 - 1s - loss: 69.2808 - mae: 5.9508 - r2_keras: 0.9808 - val_loss: 2688.2517 - val_mae: 33.5532 - val_r2_keras: -1.8653e-02 - 866ms/epoch - 11ms/step\n",
            "Epoch 50/110\n",
            "80/80 - 1s - loss: 65.1279 - mae: 5.8102 - r2_keras: 0.9821 - val_loss: 2670.0178 - val_mae: 33.3336 - val_r2_keras: 0.1400 - 852ms/epoch - 11ms/step\n",
            "Epoch 51/110\n",
            "80/80 - 1s - loss: 64.9474 - mae: 5.7449 - r2_keras: 0.9822 - val_loss: 2488.8687 - val_mae: 32.5291 - val_r2_keras: 0.1924 - 820ms/epoch - 10ms/step\n",
            "Epoch 52/110\n",
            "80/80 - 1s - loss: 60.7695 - mae: 5.5827 - r2_keras: 0.9832 - val_loss: 2495.3667 - val_mae: 32.4964 - val_r2_keras: 0.2324 - 789ms/epoch - 10ms/step\n",
            "Epoch 53/110\n",
            "80/80 - 1s - loss: 57.1120 - mae: 5.4454 - r2_keras: 0.9842 - val_loss: 2545.4873 - val_mae: 32.8296 - val_r2_keras: 0.1152 - 824ms/epoch - 10ms/step\n",
            "Epoch 54/110\n",
            "80/80 - 1s - loss: 60.9170 - mae: 5.6150 - r2_keras: 0.9832 - val_loss: 2585.3298 - val_mae: 33.1797 - val_r2_keras: 0.0957 - 832ms/epoch - 10ms/step\n",
            "Epoch 55/110\n",
            "80/80 - 1s - loss: 73.9990 - mae: 6.1160 - r2_keras: 0.9795 - val_loss: 2368.7446 - val_mae: 32.0925 - val_r2_keras: 0.2352 - 793ms/epoch - 10ms/step\n",
            "Epoch 56/110\n",
            "80/80 - 1s - loss: 57.9258 - mae: 5.4725 - r2_keras: 0.9840 - val_loss: 2459.2146 - val_mae: 32.1965 - val_r2_keras: 0.2081 - 809ms/epoch - 10ms/step\n",
            "Epoch 57/110\n",
            "80/80 - 1s - loss: 60.7818 - mae: 5.5935 - r2_keras: 0.9830 - val_loss: 2574.1340 - val_mae: 33.3653 - val_r2_keras: 0.0943 - 822ms/epoch - 10ms/step\n",
            "Epoch 58/110\n",
            "80/80 - 1s - loss: 55.8900 - mae: 5.3590 - r2_keras: 0.9845 - val_loss: 2586.9133 - val_mae: 33.2840 - val_r2_keras: 0.2126 - 841ms/epoch - 11ms/step\n",
            "Epoch 59/110\n",
            "80/80 - 1s - loss: 56.6880 - mae: 5.3672 - r2_keras: 0.9843 - val_loss: 2556.9099 - val_mae: 32.7768 - val_r2_keras: 0.1961 - 1s/epoch - 15ms/step\n",
            "Epoch 60/110\n",
            "80/80 - 1s - loss: 52.3505 - mae: 5.1736 - r2_keras: 0.9855 - val_loss: 2474.4719 - val_mae: 32.6363 - val_r2_keras: 0.1502 - 1s/epoch - 16ms/step\n",
            "Epoch 61/110\n",
            "80/80 - 1s - loss: 57.6755 - mae: 5.3864 - r2_keras: 0.9840 - val_loss: 2652.0071 - val_mae: 33.6507 - val_r2_keras: 0.0688 - 1s/epoch - 16ms/step\n",
            "Epoch 62/110\n",
            "80/80 - 1s - loss: 54.6883 - mae: 5.2796 - r2_keras: 0.9848 - val_loss: 2649.4038 - val_mae: 33.1052 - val_r2_keras: 0.1565 - 893ms/epoch - 11ms/step\n",
            "Epoch 63/110\n",
            "80/80 - 1s - loss: 57.2259 - mae: 5.4303 - r2_keras: 0.9842 - val_loss: 2583.3242 - val_mae: 33.2549 - val_r2_keras: 0.1722 - 834ms/epoch - 10ms/step\n",
            "Epoch 64/110\n",
            "80/80 - 1s - loss: 51.1267 - mae: 5.1005 - r2_keras: 0.9859 - val_loss: 2402.1028 - val_mae: 32.2441 - val_r2_keras: 0.2738 - 844ms/epoch - 11ms/step\n",
            "Epoch 65/110\n",
            "80/80 - 1s - loss: 51.9363 - mae: 5.1338 - r2_keras: 0.9856 - val_loss: 2512.7651 - val_mae: 32.7153 - val_r2_keras: 0.0900 - 845ms/epoch - 11ms/step\n",
            "Epoch 66/110\n",
            "80/80 - 1s - loss: 52.1140 - mae: 5.1286 - r2_keras: 0.9855 - val_loss: 2504.0261 - val_mae: 32.7482 - val_r2_keras: 0.2878 - 864ms/epoch - 11ms/step\n",
            "Epoch 67/110\n",
            "80/80 - 1s - loss: 49.4062 - mae: 5.0552 - r2_keras: 0.9863 - val_loss: 2511.0916 - val_mae: 32.3177 - val_r2_keras: 0.1648 - 838ms/epoch - 10ms/step\n",
            "Epoch 68/110\n",
            "80/80 - 1s - loss: 47.7498 - mae: 4.9004 - r2_keras: 0.9868 - val_loss: 2605.3000 - val_mae: 33.4883 - val_r2_keras: 0.0638 - 863ms/epoch - 11ms/step\n",
            "Epoch 69/110\n",
            "80/80 - 1s - loss: 45.0622 - mae: 4.8124 - r2_keras: 0.9875 - val_loss: 2452.8030 - val_mae: 32.6004 - val_r2_keras: 0.2813 - 883ms/epoch - 11ms/step\n",
            "Epoch 70/110\n",
            "80/80 - 1s - loss: 49.0798 - mae: 4.9732 - r2_keras: 0.9864 - val_loss: 2536.9880 - val_mae: 33.0430 - val_r2_keras: 0.1839 - 819ms/epoch - 10ms/step\n",
            "Epoch 71/110\n",
            "80/80 - 1s - loss: 50.0201 - mae: 4.9973 - r2_keras: 0.9862 - val_loss: 2585.2815 - val_mae: 32.9000 - val_r2_keras: 0.0440 - 848ms/epoch - 11ms/step\n",
            "Epoch 72/110\n",
            "80/80 - 1s - loss: 49.2711 - mae: 5.0202 - r2_keras: 0.9863 - val_loss: 2599.2317 - val_mae: 33.4624 - val_r2_keras: 0.0926 - 798ms/epoch - 10ms/step\n",
            "Epoch 73/110\n",
            "80/80 - 1s - loss: 45.5608 - mae: 4.7856 - r2_keras: 0.9874 - val_loss: 2775.7520 - val_mae: 34.6326 - val_r2_keras: 0.1166 - 1s/epoch - 13ms/step\n",
            "Epoch 74/110\n",
            "80/80 - 1s - loss: 47.2593 - mae: 4.8182 - r2_keras: 0.9869 - val_loss: 2720.1011 - val_mae: 33.5017 - val_r2_keras: -5.5111e-02 - 1s/epoch - 15ms/step\n",
            "Epoch 75/110\n",
            "80/80 - 1s - loss: 46.8490 - mae: 4.8111 - r2_keras: 0.9870 - val_loss: 2609.6426 - val_mae: 33.2934 - val_r2_keras: 0.0416 - 1s/epoch - 16ms/step\n",
            "Epoch 76/110\n",
            "80/80 - 1s - loss: 45.2967 - mae: 4.7774 - r2_keras: 0.9875 - val_loss: 2546.0295 - val_mae: 33.0404 - val_r2_keras: 0.0870 - 906ms/epoch - 11ms/step\n",
            "Epoch 77/110\n",
            "80/80 - 1s - loss: 43.8781 - mae: 4.6854 - r2_keras: 0.9879 - val_loss: 2706.3716 - val_mae: 33.4426 - val_r2_keras: 0.1444 - 818ms/epoch - 10ms/step\n",
            "Epoch 78/110\n",
            "80/80 - 1s - loss: 42.1983 - mae: 4.6215 - r2_keras: 0.9883 - val_loss: 2658.8140 - val_mae: 33.5703 - val_r2_keras: -9.6216e-02 - 816ms/epoch - 10ms/step\n",
            "Epoch 79/110\n",
            "80/80 - 1s - loss: 50.1296 - mae: 4.8932 - r2_keras: 0.9861 - val_loss: 2576.3594 - val_mae: 33.0366 - val_r2_keras: 0.0894 - 869ms/epoch - 11ms/step\n",
            "Epoch 80/110\n",
            "80/80 - 1s - loss: 60.3101 - mae: 5.3470 - r2_keras: 0.9835 - val_loss: 2477.3420 - val_mae: 32.5691 - val_r2_keras: 0.1873 - 810ms/epoch - 10ms/step\n",
            "Epoch 81/110\n",
            "80/80 - 1s - loss: 43.7981 - mae: 4.6661 - r2_keras: 0.9879 - val_loss: 2510.1863 - val_mae: 32.4595 - val_r2_keras: 0.2652 - 787ms/epoch - 10ms/step\n",
            "Epoch 82/110\n",
            "80/80 - 1s - loss: 42.5666 - mae: 4.6108 - r2_keras: 0.9883 - val_loss: 2676.6235 - val_mae: 33.6249 - val_r2_keras: 0.0266 - 801ms/epoch - 10ms/step\n",
            "Epoch 83/110\n",
            "80/80 - 1s - loss: 41.9500 - mae: 4.5397 - r2_keras: 0.9884 - val_loss: 2584.8110 - val_mae: 32.8861 - val_r2_keras: 0.2321 - 820ms/epoch - 10ms/step\n",
            "Epoch 84/110\n",
            "80/80 - 1s - loss: 40.0122 - mae: 4.4638 - r2_keras: 0.9889 - val_loss: 2607.6953 - val_mae: 32.9670 - val_r2_keras: 0.0872 - 798ms/epoch - 10ms/step\n",
            "Epoch 85/110\n",
            "80/80 - 1s - loss: 41.8372 - mae: 4.5368 - r2_keras: 0.9884 - val_loss: 2502.3914 - val_mae: 32.9015 - val_r2_keras: 0.1214 - 855ms/epoch - 11ms/step\n",
            "Epoch 86/110\n",
            "80/80 - 1s - loss: 39.6307 - mae: 4.4428 - r2_keras: 0.9890 - val_loss: 2645.1057 - val_mae: 33.5106 - val_r2_keras: 0.0619 - 928ms/epoch - 12ms/step\n",
            "Epoch 87/110\n",
            "80/80 - 1s - loss: 38.4232 - mae: 4.3201 - r2_keras: 0.9894 - val_loss: 2657.0095 - val_mae: 33.8462 - val_r2_keras: 0.0663 - 800ms/epoch - 10ms/step\n",
            "Epoch 88/110\n",
            "80/80 - 1s - loss: 38.7495 - mae: 4.3901 - r2_keras: 0.9893 - val_loss: 2535.5410 - val_mae: 32.5433 - val_r2_keras: 0.2194 - 1s/epoch - 13ms/step\n",
            "Epoch 89/110\n",
            "80/80 - 1s - loss: 39.9316 - mae: 4.4077 - r2_keras: 0.9890 - val_loss: 2420.9805 - val_mae: 32.5292 - val_r2_keras: 0.2315 - 1s/epoch - 14ms/step\n",
            "Epoch 90/110\n",
            "80/80 - 1s - loss: 36.7734 - mae: 4.2920 - r2_keras: 0.9898 - val_loss: 2566.4165 - val_mae: 33.1750 - val_r2_keras: 0.0758 - 1s/epoch - 14ms/step\n",
            "Epoch 91/110\n",
            "80/80 - 1s - loss: 37.4247 - mae: 4.2951 - r2_keras: 0.9897 - val_loss: 2622.8997 - val_mae: 33.2779 - val_r2_keras: 0.1247 - 1s/epoch - 16ms/step\n",
            "Epoch 92/110\n",
            "80/80 - 1s - loss: 37.9820 - mae: 4.3497 - r2_keras: 0.9895 - val_loss: 2491.6309 - val_mae: 32.4571 - val_r2_keras: 0.1425 - 792ms/epoch - 10ms/step\n",
            "Epoch 93/110\n",
            "80/80 - 1s - loss: 42.9362 - mae: 4.5583 - r2_keras: 0.9881 - val_loss: 2604.8572 - val_mae: 33.2271 - val_r2_keras: 0.0984 - 777ms/epoch - 10ms/step\n",
            "Epoch 94/110\n",
            "80/80 - 1s - loss: 36.5760 - mae: 4.2473 - r2_keras: 0.9899 - val_loss: 2570.3235 - val_mae: 33.0480 - val_r2_keras: 0.1454 - 799ms/epoch - 10ms/step\n",
            "Epoch 95/110\n",
            "80/80 - 1s - loss: 35.1212 - mae: 4.1371 - r2_keras: 0.9903 - val_loss: 2453.1729 - val_mae: 32.2951 - val_r2_keras: 0.3792 - 781ms/epoch - 10ms/step\n",
            "Epoch 96/110\n",
            "80/80 - 1s - loss: 36.6508 - mae: 4.2507 - r2_keras: 0.9899 - val_loss: 2692.5576 - val_mae: 33.7836 - val_r2_keras: 0.1090 - 805ms/epoch - 10ms/step\n",
            "Epoch 97/110\n",
            "80/80 - 1s - loss: 35.2667 - mae: 4.1780 - r2_keras: 0.9903 - val_loss: 2745.3208 - val_mae: 33.9852 - val_r2_keras: -2.0905e-02 - 774ms/epoch - 10ms/step\n",
            "Epoch 98/110\n",
            "80/80 - 1s - loss: 37.1886 - mae: 4.3037 - r2_keras: 0.9897 - val_loss: 2612.8948 - val_mae: 33.3445 - val_r2_keras: 0.1022 - 805ms/epoch - 10ms/step\n",
            "Epoch 99/110\n",
            "80/80 - 1s - loss: 35.1775 - mae: 4.1610 - r2_keras: 0.9902 - val_loss: 2816.6521 - val_mae: 34.5696 - val_r2_keras: -7.2302e-02 - 777ms/epoch - 10ms/step\n",
            "Epoch 100/110\n",
            "80/80 - 1s - loss: 34.6474 - mae: 4.1116 - r2_keras: 0.9905 - val_loss: 2432.3511 - val_mae: 32.1313 - val_r2_keras: 0.2517 - 782ms/epoch - 10ms/step\n",
            "Epoch 101/110\n",
            "80/80 - 1s - loss: 35.5308 - mae: 4.1729 - r2_keras: 0.9902 - val_loss: 2450.5125 - val_mae: 32.3785 - val_r2_keras: 0.1986 - 780ms/epoch - 10ms/step\n",
            "Epoch 102/110\n",
            "80/80 - 1s - loss: 33.1190 - mae: 4.0288 - r2_keras: 0.9909 - val_loss: 2537.1262 - val_mae: 32.8017 - val_r2_keras: 0.1548 - 806ms/epoch - 10ms/step\n",
            "Epoch 103/110\n",
            "80/80 - 1s - loss: 33.8036 - mae: 4.0680 - r2_keras: 0.9907 - val_loss: 2657.4524 - val_mae: 33.4608 - val_r2_keras: 0.0198 - 942ms/epoch - 12ms/step\n",
            "Epoch 104/110\n",
            "80/80 - 1s - loss: 33.0896 - mae: 4.0164 - r2_keras: 0.9909 - val_loss: 2619.5530 - val_mae: 33.0577 - val_r2_keras: 0.0951 - 1s/epoch - 15ms/step\n",
            "Epoch 105/110\n",
            "80/80 - 1s - loss: 33.8345 - mae: 4.0517 - r2_keras: 0.9907 - val_loss: 2557.8481 - val_mae: 33.2546 - val_r2_keras: 0.1209 - 1s/epoch - 15ms/step\n",
            "Epoch 106/110\n",
            "80/80 - 1s - loss: 31.2624 - mae: 3.8661 - r2_keras: 0.9914 - val_loss: 2590.6338 - val_mae: 33.1530 - val_r2_keras: 0.0975 - 986ms/epoch - 12ms/step\n",
            "Epoch 107/110\n",
            "80/80 - 1s - loss: 34.0300 - mae: 4.0272 - r2_keras: 0.9905 - val_loss: 2521.9329 - val_mae: 32.6980 - val_r2_keras: 0.0998 - 816ms/epoch - 10ms/step\n",
            "Epoch 108/110\n",
            "80/80 - 1s - loss: 35.5989 - mae: 4.2230 - r2_keras: 0.9901 - val_loss: 2518.7019 - val_mae: 32.5289 - val_r2_keras: 0.1331 - 810ms/epoch - 10ms/step\n",
            "Epoch 109/110\n",
            "80/80 - 1s - loss: 31.3754 - mae: 3.8818 - r2_keras: 0.9913 - val_loss: 2550.3826 - val_mae: 33.0331 - val_r2_keras: 0.2108 - 783ms/epoch - 10ms/step\n",
            "Epoch 110/110\n",
            "80/80 - 1s - loss: 30.0511 - mae: 3.8083 - r2_keras: 0.9917 - val_loss: 2813.7629 - val_mae: 34.6839 - val_r2_keras: 0.0481 - 804ms/epoch - 10ms/step\n",
            "4/4 [==============================] - 1s 8ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}